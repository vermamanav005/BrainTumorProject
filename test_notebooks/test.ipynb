{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "90c124b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "483a5e1a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cuda available: True\n"
     ]
    }
   ],
   "source": [
    "print(\"Cuda available:\", torch.cuda.is_available())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "9ae31bf5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GPU NVIDIA GeForce GTX 1650\n"
     ]
    }
   ],
   "source": [
    "print(\"GPU\", torch.cuda.get_device_name(0) if torch.cuda.is_available() else \"No GPU found\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "95dc3ead",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 369 patient folders in: C:\\Users\\manav\\Downloads\\archive\\BraTS2020_TrainingData\\MICCAI_BraTS2020_TrainingData\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Inspecting patients: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 369/369 [00:50<00:00,  7.37it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "SUMMARY:\n",
      "  Patients inspected: 369\n",
      "  Patients missing seg: 1\n",
      "  Avg slices per volume (approx): 155.0\n",
      "  Avg % of slices with tumor (for patients with seg): 42.70%\n",
      "\n",
      "CSV saved at: outputs\\inspect\\summary.csv\n",
      "JSON saved at: outputs\\inspect\\summary.json\n",
      "Previews saved at: outputs\\inspect\\previews\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "inspect_brats_dataset.py\n",
    "\n",
    "Scan BraTS training dataset structure, verify all modalities, segmentation files,\n",
    "and compute tumor slice statistics. Saves per-patient summary in CSV + JSON and\n",
    "optionally saves 3-slice preview PNGs.\n",
    "\n",
    "Usage:\n",
    "    python scripts/inspect_brats_dataset.py\n",
    "\"\"\"\n",
    "\n",
    "import os\n",
    "import glob\n",
    "import csv\n",
    "import json\n",
    "import argparse\n",
    "from tqdm import tqdm\n",
    "import numpy as np\n",
    "import nibabel as nib\n",
    "import cv2\n",
    "\n",
    "# -------------------------------\n",
    "# âœ… CONFIGURATION (use raw strings on Windows)\n",
    "# -------------------------------\n",
    "BRA_TS_PATH = r\"C:\\Users\\manav\\Downloads\\archive\\BraTS2020_TrainingData\\MICCAI_BraTS2020_TrainingData\"\n",
    "OUTPUT_DIR = r\"outputs\\inspect\"\n",
    "SAVE_PREVIEWS = True   # Set to False to skip image previews\n",
    "MAX_PATIENTS = None    # e.g., 5 for quick test, or None for all\n",
    "\n",
    "# -------------------------------\n",
    "# ðŸ”§ HELPER FUNCTIONS\n",
    "# -------------------------------\n",
    "def find_modality_file(patient_dir, pattern):\n",
    "    matches = glob.glob(os.path.join(patient_dir, pattern))\n",
    "    return matches[0] if matches else None\n",
    "\n",
    "def normalize_uint8(img2d):\n",
    "    img = np.nan_to_num(img2d)\n",
    "    mn, mx = img.min(), img.max()\n",
    "    if mx - mn < 1e-6:\n",
    "        return (np.zeros_like(img) * 255).astype(np.uint8)\n",
    "    norm = (img - mn) / (mx - mn)\n",
    "    return (norm * 255).astype(np.uint8)\n",
    "\n",
    "def make_preview(slice_list, outpath):\n",
    "    imgs_rgb = []\n",
    "    for s in slice_list:\n",
    "        if s.ndim == 2:\n",
    "            imgs_rgb.append(cv2.cvtColor(s, cv2.COLOR_GRAY2BGR))\n",
    "        else:\n",
    "            imgs_rgb.append(s)\n",
    "    preview = np.hstack(imgs_rgb)\n",
    "    cv2.imwrite(outpath, preview)\n",
    "\n",
    "def inspect_patient(patient_dir, patient_name, save_previews=False, preview_outdir=None):\n",
    "    patterns = {\n",
    "        \"t1\": f\"{patient_name}*t1.nii*\",\n",
    "        \"t1ce\": f\"{patient_name}*t1ce.nii*\",\n",
    "        \"t2\": f\"{patient_name}*t2.nii*\",\n",
    "        \"flair\": f\"{patient_name}*flair.nii*\",\n",
    "        \"seg\": f\"{patient_name}*seg.nii*\",\n",
    "    }\n",
    "\n",
    "    info = {\"patient\": patient_name}\n",
    "    for key, pat in patterns.items():\n",
    "        f = find_modality_file(patient_dir, pat)\n",
    "        info[f\"{key}_file\"] = f if f else \"\"\n",
    "        info[f\"{key}_present\"] = bool(f)\n",
    "\n",
    "    for key in [\"t1\", \"t1ce\", \"t2\", \"flair\", \"seg\"]:\n",
    "        f = info.get(f\"{key}_file\")\n",
    "        if f:\n",
    "            try:\n",
    "                nii = nib.load(f)\n",
    "                shape = tuple(nii.header.get_data_shape())\n",
    "                while len(shape) > 3 and shape[-1] == 1:\n",
    "                    shape = shape[:-1]\n",
    "                info[f\"{key}_shape\"] = shape\n",
    "                info[f\"{key}_slices\"] = int(shape[2]) if len(shape) >= 3 else 0\n",
    "            except Exception as e:\n",
    "                info[f\"{key}_shape\"] = None\n",
    "                info[f\"{key}_slices\"] = 0\n",
    "                info[f\"{key}_error\"] = str(e)\n",
    "        else:\n",
    "            info[f\"{key}_shape\"] = None\n",
    "            info[f\"{key}_slices\"] = 0\n",
    "\n",
    "    # tumor slice computation\n",
    "    seg_file = info.get(\"seg_file\")\n",
    "    if seg_file:\n",
    "        try:\n",
    "            seg_nii = nib.load(seg_file)\n",
    "            seg_arr = seg_nii.get_fdata().astype(np.int16)\n",
    "            if seg_arr.ndim >= 3:\n",
    "                axis_slices = seg_arr.shape[2]\n",
    "                tumor_mask_per_slice = np.any(seg_arr > 0, axis=(0, 1))\n",
    "                tumor_slices = int(np.count_nonzero(tumor_mask_per_slice))\n",
    "                tumor_pct = float(tumor_slices / max(1, axis_slices) * 100.0)\n",
    "                info[\"tumor_slices\"] = tumor_slices\n",
    "                info[\"tumor_pct\"] = tumor_pct\n",
    "            else:\n",
    "                info[\"tumor_slices\"] = 0\n",
    "                info[\"tumor_pct\"] = 0.0\n",
    "        except Exception as ex:\n",
    "            info[\"tumor_slices\"] = None\n",
    "            info[\"tumor_pct\"] = None\n",
    "            info[\"seg_error\"] = str(ex)\n",
    "    else:\n",
    "        info[\"tumor_slices\"] = None\n",
    "        info[\"tumor_pct\"] = None\n",
    "\n",
    "    if save_previews and preview_outdir:\n",
    "        for pref in [\"t1ce\", \"flair\", \"t1\", \"t2\"]:\n",
    "            f = info.get(f\"{pref}_file\")\n",
    "            if f:\n",
    "                try:\n",
    "                    nii = nib.load(f)\n",
    "                    arr = nii.get_fdata()\n",
    "                    if arr.ndim < 3:\n",
    "                        break\n",
    "                    s0 = 0\n",
    "                    s1 = arr.shape[2] // 2\n",
    "                    s2 = max(0, arr.shape[2] - 1)\n",
    "                    slices = [normalize_uint8(arr[:, :, s]) for s in [s0, s1, s2]]\n",
    "                    os.makedirs(preview_outdir, exist_ok=True)\n",
    "                    outname = os.path.join(preview_outdir, f\"{patient_name}_{pref}_preview.png\")\n",
    "                    make_preview(slices, outname)\n",
    "                    info[\"preview_saved\"] = outname\n",
    "                except Exception as e:\n",
    "                    info[\"preview_saved\"] = \"\"\n",
    "                    info[\"preview_error\"] = str(e)\n",
    "                break\n",
    "\n",
    "    return info\n",
    "\n",
    "# -------------------------------\n",
    "# ðŸ§  MAIN\n",
    "# -------------------------------\n",
    "if __name__ == \"__main__\":\n",
    "    os.makedirs(OUTPUT_DIR, exist_ok=True)\n",
    "    preview_dir = os.path.join(OUTPUT_DIR, \"previews\")\n",
    "\n",
    "    patients = [d for d in os.listdir(BRA_TS_PATH) if os.path.isdir(os.path.join(BRA_TS_PATH, d))]\n",
    "    patients.sort()\n",
    "    if MAX_PATIENTS:\n",
    "        patients = patients[:MAX_PATIENTS]\n",
    "\n",
    "    print(f\"Found {len(patients)} patient folders in: {BRA_TS_PATH}\")\n",
    "\n",
    "    summary = []\n",
    "    for patient in tqdm(patients, desc=\"Inspecting patients\"):\n",
    "        patient_path = os.path.join(BRA_TS_PATH, patient)\n",
    "        info = inspect_patient(patient_path, patient, save_previews=SAVE_PREVIEWS, preview_outdir=preview_dir)\n",
    "        summary.append(info)\n",
    "\n",
    "    # write summary.csv\n",
    "    csv_fields = sorted(list({k for d in summary for k in d.keys()}))\n",
    "    csv_path = os.path.join(OUTPUT_DIR, \"summary.csv\")\n",
    "    with open(csv_path, \"w\", newline=\"\", encoding=\"utf-8\") as cf:\n",
    "        writer = csv.DictWriter(cf, fieldnames=csv_fields)\n",
    "        writer.writeheader()\n",
    "        for row in summary:\n",
    "            writer.writerow(row)\n",
    "\n",
    "    # write summary.json\n",
    "    json_path = os.path.join(OUTPUT_DIR, \"summary.json\")\n",
    "    with open(json_path, \"w\", encoding=\"utf-8\") as jf:\n",
    "        json.dump(summary, jf, indent=2)\n",
    "\n",
    "    # print quick summary\n",
    "    total = len(summary)\n",
    "    missing_seg = sum(1 for s in summary if not s.get(\"seg_present\"))\n",
    "    avg_slices = np.mean([\n",
    "        s.get(\"t1ce_slices\") or s.get(\"t1_slices\") or s.get(\"t2_slices\") or s.get(\"flair_slices\") or 0\n",
    "        for s in summary\n",
    "    ])\n",
    "    avg_tumor_pct = np.nanmean([s[\"tumor_pct\"] for s in summary if s.get(\"tumor_pct\") not in (None,)])\n",
    "    print(\"\\nSUMMARY:\")\n",
    "    print(f\"  Patients inspected: {total}\")\n",
    "    print(f\"  Patients missing seg: {missing_seg}\")\n",
    "    print(f\"  Avg slices per volume (approx): {avg_slices:.1f}\")\n",
    "    print(f\"  Avg % of slices with tumor (for patients with seg): {avg_tumor_pct:.2f}%\")\n",
    "    print(f\"\\nCSV saved at: {csv_path}\")\n",
    "    print(f\"JSON saved at: {json_path}\")\n",
    "    if SAVE_PREVIEWS:\n",
    "        print(f\"Previews saved at: {preview_dir}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "1b45ae0b",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Extracting slices: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 369/369 [10:58<00:00,  1.78s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "âœ… Slice extraction complete!\n",
      "Total slices processed: 57040\n",
      "Total images saved: 57040\n",
      "Output saved to: dataset_slices\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "extract_slices_for_efficientnet_fixed.py\n",
    "\"\"\"\n",
    "\n",
    "import os, glob, random, shutil\n",
    "import numpy as np\n",
    "import nibabel as nib\n",
    "import cv2\n",
    "from tqdm import tqdm\n",
    "\n",
    "# ------------------------------\n",
    "# CONFIGURATION\n",
    "# ------------------------------\n",
    "DATASET_PATH = r\"C:\\Users\\manav\\Downloads\\archive\\BraTS2020_TrainingData\\MICCAI_BraTS2020_TrainingData\"\n",
    "OUTPUT_PATH = r\"dataset_slices\"\n",
    "MODALITIES = [\"t1ce\", \"t2\", \"flair\"]\n",
    "IMG_SIZE = (224, 224)\n",
    "VAL_SPLIT = 0.15\n",
    "MAX_PATIENTS = None  # set small number to test, e.g., 5\n",
    "\n",
    "# ------------------------------\n",
    "def normalize(img):\n",
    "    img = np.nan_to_num(img)\n",
    "    mn, mx = np.percentile(img, (1, 99))\n",
    "    if mx - mn < 1e-6:\n",
    "        return np.zeros_like(img)\n",
    "    img = np.clip((img - mn) / (mx - mn), 0, 1)\n",
    "    return img\n",
    "\n",
    "def ensure_dirs():\n",
    "    for split in [\"train\", \"val\"]:\n",
    "        for label in [\"tumor\", \"normal\"]:\n",
    "            os.makedirs(os.path.join(OUTPUT_PATH, split, label), exist_ok=True)\n",
    "\n",
    "def find_file(patient_path, patient_name, modality):\n",
    "    # Finds nii OR nii.gz file for the given modality\n",
    "    for ext in [\".nii.gz\", \".nii\"]:\n",
    "        files = glob.glob(os.path.join(patient_path, f\"{patient_name}_{modality}{ext}\"))\n",
    "        if files:\n",
    "            return files[0]\n",
    "    # fallback: search more broadly if naming differs\n",
    "    files = glob.glob(os.path.join(patient_path, f\"*{modality}.nii*\"))\n",
    "    return files[0] if files else None\n",
    "\n",
    "def main():\n",
    "    ensure_dirs()\n",
    "\n",
    "    patients = sorted([d for d in os.listdir(DATASET_PATH) if os.path.isdir(os.path.join(DATASET_PATH, d))])\n",
    "    if MAX_PATIENTS:\n",
    "        patients = patients[:MAX_PATIENTS]\n",
    "\n",
    "    random.shuffle(patients)\n",
    "    val_count = int(len(patients) * VAL_SPLIT)\n",
    "    val_patients = set(patients[:val_count])\n",
    "\n",
    "    total_slices = 0\n",
    "    saved_slices = 0\n",
    "\n",
    "    for patient in tqdm(patients, desc=\"Extracting slices\"):\n",
    "        pdir = os.path.join(DATASET_PATH, patient)\n",
    "        seg_path = find_file(pdir, patient, \"seg\")\n",
    "        if not seg_path:\n",
    "            continue\n",
    "\n",
    "        seg = nib.load(seg_path).get_fdata().astype(np.uint8)\n",
    "        seg_bin = (seg > 0).astype(np.uint8)\n",
    "\n",
    "        # Load all modalities\n",
    "        channels = []\n",
    "        for mod in MODALITIES:\n",
    "            f = find_file(pdir, patient, mod)\n",
    "            if f:\n",
    "                channels.append(normalize(nib.load(f).get_fdata()))\n",
    "        if len(channels) != 3:\n",
    "            continue\n",
    "\n",
    "        vol = np.stack(channels, axis=-1)  # (H, W, S, 3)\n",
    "        slices = vol.shape[2]\n",
    "\n",
    "        for z in range(slices):\n",
    "            img = vol[:, :, z, :]\n",
    "            mask = seg_bin[:, :, z]\n",
    "            label = \"tumor\" if np.any(mask) else \"normal\"\n",
    "\n",
    "            img_resized = cv2.resize((img * 255).astype(np.uint8), IMG_SIZE)\n",
    "            split = \"val\" if patient in val_patients else \"train\"\n",
    "            out_dir = os.path.join(OUTPUT_PATH, split, label)\n",
    "            out_name = f\"{patient}_z{z:03d}.png\"\n",
    "            cv2.imwrite(os.path.join(out_dir, out_name), img_resized)\n",
    "            saved_slices += 1\n",
    "        total_slices += slices\n",
    "\n",
    "    print(f\"\\nâœ… Slice extraction complete!\")\n",
    "    print(f\"Total slices processed: {total_slices}\")\n",
    "    print(f\"Total images saved: {saved_slices}\")\n",
    "    print(f\"Output saved to: {OUTPUT_PATH}\")\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "5fa73f08",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… GPU Available: True\n",
      "Using device: NVIDIA GeForce GTX 1650\n",
      "Train images: 48515 | Val images: 8525\n",
      "Classes: ['normal', 'tumor']\n",
      "\n",
      "âœ… Forward pass successful!\n",
      "Batch size: 16\n",
      "Predictions: [0 0 0 1 0 0 1 1]\n",
      "True labels: [0 1 1 1 0 1 1 1]\n"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "test_efficientnet_setup.py\n",
    "\n",
    "Quick test for EfficientNetB0 + GPU + dataset loading.\n",
    "\"\"\"\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torchvision import datasets, models, transforms\n",
    "from torch.utils.data import DataLoader\n",
    "import os\n",
    "\n",
    "# -------------------------------\n",
    "# CONFIGURATION\n",
    "# -------------------------------\n",
    "DATA_DIR = r\"C:\\Users\\manav\\Documents\\dataset_slices\"\n",
    "BATCH_SIZE = 16\n",
    "IMG_SIZE = 224\n",
    "USE_GPU = torch.cuda.is_available()\n",
    "\n",
    "print(f\"âœ… GPU Available: {USE_GPU}\")\n",
    "if USE_GPU:\n",
    "    print(f\"Using device: {torch.cuda.get_device_name(0)}\")\n",
    "\n",
    "# -------------------------------\n",
    "# DATA TRANSFORMS & LOADERS\n",
    "# -------------------------------\n",
    "transform = transforms.Compose([\n",
    "    transforms.Resize((IMG_SIZE, IMG_SIZE)),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize([0.485, 0.456, 0.406],\n",
    "                         [0.229, 0.224, 0.225])\n",
    "])\n",
    "\n",
    "train_dir = os.path.join(DATA_DIR, \"train\")\n",
    "val_dir = os.path.join(DATA_DIR, \"val\")\n",
    "\n",
    "train_data = datasets.ImageFolder(train_dir, transform=transform)\n",
    "val_data = datasets.ImageFolder(val_dir, transform=transform)\n",
    "\n",
    "train_loader = DataLoader(train_data, batch_size=BATCH_SIZE, shuffle=True, num_workers=0)\n",
    "val_loader = DataLoader(val_data, batch_size=BATCH_SIZE, shuffle=False, num_workers=0)\n",
    "\n",
    "print(f\"Train images: {len(train_data)} | Val images: {len(val_data)}\")\n",
    "print(f\"Classes: {train_data.classes}\")\n",
    "\n",
    "# -------------------------------\n",
    "# MODEL SETUP\n",
    "# -------------------------------\n",
    "model = models.efficientnet_b0(weights=\"IMAGENET1K_V1\")\n",
    "num_ftrs = model.classifier[1].in_features\n",
    "model.classifier[1] = nn.Linear(num_ftrs, 2)  # binary classification\n",
    "\n",
    "if USE_GPU:\n",
    "    model = model.cuda()\n",
    "\n",
    "# -------------------------------\n",
    "# QUICK TEST LOOP\n",
    "# -------------------------------\n",
    "images, labels = next(iter(train_loader))\n",
    "if USE_GPU:\n",
    "    images, labels = images.cuda(), labels.cuda()\n",
    "\n",
    "with torch.no_grad():\n",
    "    outputs = model(images)\n",
    "    preds = torch.argmax(outputs, dim=1)\n",
    "\n",
    "print(f\"\\nâœ… Forward pass successful!\")\n",
    "print(f\"Batch size: {images.shape[0]}\")\n",
    "print(f\"Predictions: {preds[:8].cpu().numpy()}\")\n",
    "print(f\"True labels: {labels[:8].cpu().numpy()}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "17501a45",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… Using device: cuda\n",
      "Classes: ['normal', 'tumor'] | Train: 48515 | Val: 8525\n",
      "\n",
      "Epoch 1/10\n",
      "------------------------------\n",
      "train Loss: 0.1746 | Acc: 0.9286\n",
      "val Loss: 0.2010 | Acc: 0.9296\n",
      "ðŸ’¾ Saved best model (Acc: 0.9296)\n",
      "\n",
      "Epoch 2/10\n",
      "------------------------------\n",
      "train Loss: 0.1169 | Acc: 0.9549\n",
      "val Loss: 0.1770 | Acc: 0.9348\n",
      "ðŸ’¾ Saved best model (Acc: 0.9348)\n",
      "\n",
      "Epoch 3/10\n",
      "------------------------------\n",
      "train Loss: 0.0989 | Acc: 0.9620\n",
      "val Loss: 0.1887 | Acc: 0.9335\n",
      "\n",
      "Epoch 4/10\n",
      "------------------------------\n",
      "train Loss: 0.0813 | Acc: 0.9693\n",
      "val Loss: 0.2222 | Acc: 0.9360\n",
      "ðŸ’¾ Saved best model (Acc: 0.9360)\n",
      "\n",
      "Epoch 5/10\n",
      "------------------------------\n",
      "train Loss: 0.0708 | Acc: 0.9737\n",
      "val Loss: 0.2139 | Acc: 0.9333\n",
      "\n",
      "Epoch 6/10\n",
      "------------------------------\n",
      "train Loss: 0.0579 | Acc: 0.9778\n",
      "val Loss: 0.2393 | Acc: 0.9299\n",
      "\n",
      "Epoch 7/10\n",
      "------------------------------\n",
      "train Loss: 0.0505 | Acc: 0.9818\n",
      "val Loss: 0.2403 | Acc: 0.9391\n",
      "ðŸ’¾ Saved best model (Acc: 0.9391)\n",
      "\n",
      "Epoch 8/10\n",
      "------------------------------\n",
      "train Loss: 0.0457 | Acc: 0.9831\n",
      "val Loss: 0.2307 | Acc: 0.9361\n",
      "\n",
      "Epoch 9/10\n",
      "------------------------------\n",
      "train Loss: 0.0434 | Acc: 0.9840\n",
      "val Loss: 0.2290 | Acc: 0.9326\n",
      "\n",
      "Epoch 10/10\n",
      "------------------------------\n",
      "train Loss: 0.0372 | Acc: 0.9866\n",
      "val Loss: 0.3197 | Acc: 0.9273\n",
      "\n",
      "Training complete in 93.6 min | Best val Acc: 0.9391\n",
      "âœ… Final model saved to: efficientnetb0_best.pth\n"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "train_efficientnet_b0.py\n",
    "\n",
    "Full training script for binary tumor classification (EfficientNetB0).\n",
    "\"\"\"\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torchvision import datasets, models, transforms\n",
    "from torch.utils.data import DataLoader\n",
    "import os, time, copy\n",
    "\n",
    "# ------------------------------\n",
    "# CONFIGURATION\n",
    "# ------------------------------\n",
    "DATA_DIR = r\"C:\\Users\\manav\\Documents\\dataset_slices\"\n",
    "BATCH_SIZE = 32\n",
    "EPOCHS = 10\n",
    "IMG_SIZE = 224\n",
    "LR = 1e-4\n",
    "CHECKPOINT_PATH = \"efficientnetb0_best.pth\"\n",
    "\n",
    "USE_GPU = torch.cuda.is_available()\n",
    "device = torch.device(\"cuda\" if USE_GPU else \"cpu\")\n",
    "print(f\"âœ… Using device: {device}\")\n",
    "\n",
    "# ------------------------------\n",
    "# DATA TRANSFORMS\n",
    "# ------------------------------\n",
    "data_transforms = {\n",
    "    'train': transforms.Compose([\n",
    "        transforms.Resize((IMG_SIZE, IMG_SIZE)),\n",
    "        transforms.RandomHorizontalFlip(),\n",
    "        transforms.RandomRotation(10),\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize([0.485, 0.456, 0.406],\n",
    "                             [0.229, 0.224, 0.225])\n",
    "    ]),\n",
    "    'val': transforms.Compose([\n",
    "        transforms.Resize((IMG_SIZE, IMG_SIZE)),\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize([0.485, 0.456, 0.406],\n",
    "                             [0.229, 0.224, 0.225])\n",
    "    ])\n",
    "}\n",
    "\n",
    "image_datasets = {\n",
    "    'train': datasets.ImageFolder(os.path.join(DATA_DIR, 'train'), data_transforms['train']),\n",
    "    'val': datasets.ImageFolder(os.path.join(DATA_DIR, 'val'), data_transforms['val'])\n",
    "}\n",
    "dataloaders = {\n",
    "    'train': DataLoader(image_datasets['train'], batch_size=BATCH_SIZE, shuffle=True, num_workers=0),\n",
    "    'val': DataLoader(image_datasets['val'], batch_size=BATCH_SIZE, shuffle=False, num_workers=0)\n",
    "}\n",
    "dataset_sizes = {x: len(image_datasets[x]) for x in ['train', 'val']}\n",
    "class_names = image_datasets['train'].classes\n",
    "print(f\"Classes: {class_names} | Train: {dataset_sizes['train']} | Val: {dataset_sizes['val']}\")\n",
    "\n",
    "# ------------------------------\n",
    "# MODEL SETUP\n",
    "# ------------------------------\n",
    "model = models.efficientnet_b0(weights=\"IMAGENET1K_V1\")\n",
    "num_ftrs = model.classifier[1].in_features\n",
    "model.classifier[1] = nn.Linear(num_ftrs, 2)\n",
    "model = model.to(device)\n",
    "\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.Adam(model.parameters(), lr=LR)\n",
    "\n",
    "# ------------------------------\n",
    "# TRAINING LOOP\n",
    "# ------------------------------\n",
    "best_model_wts = copy.deepcopy(model.state_dict())\n",
    "best_acc = 0.0\n",
    "start_time = time.time()\n",
    "\n",
    "for epoch in range(EPOCHS):\n",
    "    print(f\"\\nEpoch {epoch+1}/{EPOCHS}\")\n",
    "    print(\"-\" * 30)\n",
    "\n",
    "    for phase in ['train', 'val']:\n",
    "        if phase == 'train':\n",
    "            model.train()\n",
    "        else:\n",
    "            model.eval()\n",
    "\n",
    "        running_loss, running_corrects = 0.0, 0\n",
    "\n",
    "        for inputs, labels in dataloaders[phase]:\n",
    "            inputs, labels = inputs.to(device), labels.to(device)\n",
    "            optimizer.zero_grad()\n",
    "\n",
    "            with torch.set_grad_enabled(phase == 'train'):\n",
    "                outputs = model(inputs)\n",
    "                loss = criterion(outputs, labels)\n",
    "                _, preds = torch.max(outputs, 1)\n",
    "\n",
    "                if phase == 'train':\n",
    "                    loss.backward()\n",
    "                    optimizer.step()\n",
    "\n",
    "            running_loss += loss.item() * inputs.size(0)\n",
    "            running_corrects += torch.sum(preds == labels.data)\n",
    "\n",
    "        epoch_loss = running_loss / dataset_sizes[phase]\n",
    "        epoch_acc = running_corrects.double() / dataset_sizes[phase]\n",
    "\n",
    "        print(f\"{phase} Loss: {epoch_loss:.4f} | Acc: {epoch_acc:.4f}\")\n",
    "\n",
    "        # deep copy the model\n",
    "        if phase == 'val' and epoch_acc > best_acc:\n",
    "            best_acc = epoch_acc\n",
    "            best_model_wts = copy.deepcopy(model.state_dict())\n",
    "            torch.save(best_model_wts, CHECKPOINT_PATH)\n",
    "            print(f\"ðŸ’¾ Saved best model (Acc: {best_acc:.4f})\")\n",
    "\n",
    "total_time = (time.time() - start_time) / 60\n",
    "print(f\"\\nTraining complete in {total_time:.1f} min | Best val Acc: {best_acc:.4f}\")\n",
    "model.load_state_dict(best_model_wts)\n",
    "torch.save(model.state_dict(), CHECKPOINT_PATH)\n",
    "print(f\"âœ… Final model saved to: {CHECKPOINT_PATH}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "fcd50abb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Complete patients: 0\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "\n",
    "root = r\"C:\\Users\\manav\\Downloads\\archive\\BraTS2020_TrainingData\\MICCAI_BraTS2020_TrainingData\"\n",
    "complete = 0\n",
    "for pid in os.listdir(root):\n",
    "    pdir = os.path.join(root, pid)\n",
    "    if not os.path.isdir(pdir):\n",
    "        continue\n",
    "    needed = [f\"{pid}_t1ce.nii.gz\", f\"{pid}_t2.nii.gz\", f\"{pid}_flair.nii.gz\", f\"{pid}_seg.nii.gz\"]\n",
    "    if all(os.path.exists(os.path.join(pdir, n)) for n in needed):\n",
    "        complete += 1\n",
    "print(f\"Complete patients: {complete}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d85a1771",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "efficientnet",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
